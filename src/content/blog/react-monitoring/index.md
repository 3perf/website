---
title: 'Get Fast, Stay Fast: How To Monitor React Render Performance'
description: 'So you just made your app fast. Now, how do you ensure it doesnâ€™t get slow again?'
author:
  id: iamakulov
  name: Ivan Akulov
  link: https://twitter.com/iamakulov
  twitterId: iamakulov
  facebookId: '100002052594007'
socialImage:
  facebook: './cover-facebook.png'
  twitter: './cover-twitter.png'
date:
  published: 2022-06-06T15:00:00
  modified: 2022-06-08T16:00:00
# The article slug changed; letâ€™s keep its original guid to avoid pushing a new RSS item
rssForceGuid: https://3perf.com/blog/runtime-perf/
---

Say you just finished optimizing your React app and making every button click as fast as possible. Now, you want to keep an eye on the appâ€™s performance â€“ and learn if the app gets slower again so you can fix it.

Hereâ€™s how to do that.

```toc
# This code block gets replaced with the TOC
header: Contents
```

# No Ready-To-Go Solutions

Tracking React render performance is challenging. With loading performance, thereâ€™s a [whole lot](https://treo.sh) of [tools](https://github.com/GoogleChrome/lighthouse-ci) you [could](https://github.com/GoogleChrome/web-vitals#send-the-results-to-google-analytics) just [plug in](https://www.speedcurve.com) and [start](https://sentry.io/for/web-vitals/) collecting [data](https://www.webpagetest.org). Thereâ€™s nothing like that for render performance.

To track how your app behaves _after_ it loads, youâ€™d need to do some work.

[[note]]
| **Disclaimer: the solution below is not battle-tested.** These steps are based on the experiences of clients I worked with, plus my experiments in the field. Itâ€™s how I would approach setting up performance tests today. However, I havenâ€™t had a chance to implement this in a real-world app myself yet.
|
| This means I might not be aware of some edge cases or pitfalls. This guide should be a good starting point for setting up your monitoring system, but it might (or might not!) need fine-tuning to be useful.
|
| (Have your experience to add? Please [share it on Twitter](https://twitter.com/iamakulov/status/1533885339168714752)!)

# Step 1: Pick the Most Important Interactions

Before you start monitoring render performance, you need to decide _what_ to monitor.

For that, pick the interactions you care about the most. For example, for an app like Gmail, that could be:

- Clicking the â€œComposeâ€ button
- Opening an email thread
- Typing in the search field

![](./gmail.png)

# Step 2: Instrument Every Interaction

For every interaction, find the moment when it starts â€“ and wrap it with code that would measure its duration.

Hereâ€™s how this might look with Gmailâ€™s Compose button:

<!-- prettier-ignore -->
[[sidenote|[afterFrame docs](https://github.com/andrewiggins/afterframe)]]
| ```js
| import afterFrame from 'afterframe';
|
| function measureInteraction() {
|   // performance.now() returns the number of ms
|   // elapsed since the page was opened
|   const startTimestamp = performance.now();
|
|   return {
|     end() {
|       const endTimestamp = performance.now();
|       console.log('The interaction took', endTimestamp - startTimestamp, 'ms');
|     },
|   };
| }
|
| const ComposeButton = () => {
|   const handleClick = () => {
|     const interaction = measureInteraction();
|
|     // The afterFrame library calls the function
|     // when the next frame starts
|     afterFrame(() => {
|       interaction.end();
|     });
|
|     openComposePane();
|   };
|
|   return <Button onClick={handleClick}>Compose</Button>;
| };
| ```

This code will execute `measureInteraction()`, then open the compose pane, then paint the update on the screen, and _then_ call `interaction.end()`:

![](./frame-structure.png)

### Why use `afterFrame`?

[`afterFrame`](https://github.com/andrewiggins/afterframe) was specifically designed to take a function and run it right after the current frame ends. With `afterFrame`, we end up measuring the whole duration of the interaction â€“ including the time it takes for the browser to prepare and apply updates on the screen.

Compare this with e.g. `requestAnimationFrame`. A callback you pass into `requestAnimationFrame` executes either before â€œRecalculate styles & layoutâ€ or before â€œPaintâ€, depending on the browser. As a result, the measurement omits one or several parts of the browserâ€™s processing:

![{caption: "Tested with Chrome 101, Safari 15, Firefox 101. Chromeâ€™s behavior <a href='https://medium.com/@paul_irish/requestanimationframe-scheduling-for-nerds-9c57f7438ef4'>matched Firefoxâ€™s one</a> as recently as a few months ago â€“ but apparently, something has changed."}](./rAF.png)

`setTimeout(..., 0)`, `Promise.resolve().then()` and other straightforward solutions also struggle from similar issues. See [â€œAccurately measuring layout on the webâ€](https://nolanlawson.com/2018/09/25/accurately-measuring-layout-on-the-web/) by Nolan Lawson for more.

### Why not `useEffect`?

Most of the time, a function youâ€™d pass into `useEffect` would be called at the beginning of the next frame â€“ just like `afterFrame`.

However, with React 18, if the app updates in response to user input, [`useEffect` fires synchronously](https://github.com/reactwg/react-18/discussions/128). And even with React 17 and below, a `useEffect` will also run early if [you have scheduled several renders in a row](https://stackoverflow.com/a/53048903/1192426).

### Why not `performance.mark()`/`performance.measure()`?

Instead of using `performance.now()` to measure how long an interaction took, you could also use [`performance.mark()`](http://developer.mozilla.org/en-US/docs/Web/API/Performance/mark) and [`performance.measure()`](http://developer.mozilla.org/en-US/docs/Web/API/Performance/measure) APIs:

```js
function measureInteraction(interactionName) {
  // Donâ€™t do this
  performance.mark(interactionName + ' start');

  return {
    end() {
      performance.mark(interactionName + ' end');
      const measure = performance.measure(
        interactionName + ' duration',
        interactionName + ' start',
        interactionName + ' end',
      );
      console.log('The interaction took', measure.duration, 'ms');
    },
  };
}
```

This has a useful side effect. `performance.measure()` entries are visible in Chrome DevTools, which makes debugging performance issues easier:

![](./user-timings.png)

However, in Chrome, `performance.measure()` calls consume _a lot_ of memory. In my tests, creating 5000 `performance.measure()` entries causes the browserâ€™s tab to increase its memory usage by ~100 MB. And if your app stays open for a while â€“ like Gmail or Figma â€“ 5000 entries is not that much!

### How does this work with React 18â€™s concurrent rendering?

This, unfortunately, doesnâ€™t. If the interaction youâ€™re trying to measure uses `useTransition` or `useDeferredValue`:

```js
const ComposeButton = () => {
  const [isTransitioning, startTransition] = useTransition();

  const handleClick = () => {
    const interaction = measureInteraction();

    afterFrame(() => {
      interaction.end();
    });

    startTransition(() => {
      openComposePane();
    });
  };

  return <Button onClick={handleClick}>Compose</Button>;
};
```

`afterFrame` will fire too early:

![](./concurrent.png)

With concurrent rendering, youâ€™d probably need to use `useEffect` instead, even though [itâ€™s imprecise](#why-not-useeffect).

# Step 3: Collect Measured Durations

[[sidenote|Other teams Iâ€™ve worked with also used [DataDog](https://www.datadoghq.com), [New Relic](https://newrelic.com), and custom solutions built upon [Google BigQuery](https://cloud.google.com/bigquery) or [AWS DynamoDB](https://aws.amazon.com/dynamodb/)]]
| With interaction measurements in place, itâ€™s time to collect and send them somewhere. My favorite tool for this is [Sentry](https://docs.sentry.io/product/performance/).

To collect performance data into Sentry, update `measureInteraction()` to use [`Sentry.startTransaction` and `transaction.finish()`](https://docs.sentry.io/platforms/javascript/guides/react/performance/instrumentation/custom-instrumentation/):

```js
function measureInteraction(interactionName) {
  const transaction = Sentry.startTransaction({ name: interactionName });

  return {
    end() {
      transaction.finish();
    },
  };
}
```

Sentry will collect the transactions you submit â€“ and show you how they change over time, whatâ€™s common between the slowest transactions, and more:

![](./sentry.png)

# Step 4: Collect Additional Data

In addition to tracking the most important interactions, consider collecting data about all long tasks and events. This is useful to see larger trends: if the number of long frames grows over time, the app is getting slower.

To collect long tasks or events, use [the `PerformanceObserver` API](http://developer.mozilla.org/en-US/docs/Web/API/PerformanceObserver):

```js
// Include the performance events to track:
// - longtask: triggered when any piece of JavaScript took more than 50 ms to execute
// - event: triggered when any event happens
// Other events: http://developer.mozilla.org/en-US/docs/Web/API/PerformanceEntry/entryType
const performanceEventsToTrack = ['longtask', 'event'];

const observer = new PerformanceObserver((list) => {
  // This callback is called whenever a new event
  // (or a series of events) occurs
  for (const entry of list.getEntries()) {
    // Skip `event` events that were cheap
    if (entry.entryType === 'event' && entry.duration < 50) continue;

    // Send the event to the data warehouse
    sendEntryToDataWarehouse(entry);
  }
});

observer.observe({ entryTypes: performanceEventsToTrack });
```

With Sentry, `sendEntryToDataWarehouse` might look like this:

```js
function sendEntryToDataWarehouse(entry) {
  if (entry.entryType === 'longtask') {
    Sentry.captureMessage('Long task', {
      level: 'info',
      contexts: {
        details: {
          duration: entry.duration,
          startTime: entry.startTime,
          // ...
        },
      },
    });
  } else {
    Sentry.captureMessage('Long event handler', {
      level: 'info',
      contexts: {
        details: {
          duration: entry.duration,
          startTime: entry.startTime,
          eventKind: entry.name, // "click" or "keypress" or etc
          target: entry.target.className,
          // ...
        },
      },
    });
  }
}
```

# Step 5: Keep An Eye On The Metrics

Now youâ€™re all set! Make sure to monitor these metrics regularly and â€“ if they get worse â€“ figure out why.

To keep the metrics on top of your mind:

- set up alerts to get notified when the metrics get worse
- or check the metrics on weekly/bi-weekly team sync-ups

# Synthetic Testing

With the steps above, youâ€™ll start collecting metrics from real users. (This is known as â€œRUMâ€, or â€œReal User Monitoringâ€.) RUM catches performance regressions right after they happen.

Sometimes, itâ€™s useful to catch regressions _before_ they happen. For example:

- You refactor the codebase and want to check how that affected the performance. You run `npm run test-perf`, and the command tells you whether the refactoring made the codebase faster or slower

- You want to ensure your team remembers to keep the app fast. You set up a CI check, and the CI immediately tells everyone if their PR breaches performance budgets

In this case, youâ€™ll need to do synthetic testing instead. Synthetic testing means â€œrunning performance tests in a virtual machine, on demandâ€. Hereâ€™s how to set it up:

1. **Pick the most important interactions.** Just like [in step 1 above](#step-1-pick-the-most-important-interactions).

2. **Set up measurements.** If you followed [step 2 above](#step-2-instrument-every-interaction) to instrument interactions, youâ€™re all good! Use that.

   Otherwise, try running Lighthouse [in the Timespan mode](https://github.com/GoogleChrome/lighthouse/blob/master/docs/user-flows.md#timespan). The Timespan mode is like the regular Lighthouse â€“ except that it measures the performance of interactions, not the loading speed.

   [[sidenote|Why use Interaction to Next Paint? Because itâ€™s specifically designed for what weâ€™re trying to achieve: to measure how quickly an interaction takes. [Docs](https://web.dev/inp/)]]
   | For example, hereâ€™s how to measure how fast the Gmailâ€™s â€œComposeâ€ button is. Open Gmail â†’ start a timespan recording â†’ click the â€œComposeâ€ button â†’ stop the recording â†’ read the _Interaction to Next Paint_ value:

   ![{caption:"This is a human-readable Lighthouse report. In case you need to extract Interaction to Next Paint automatically, Lighthouse also returns data in the JSON format. See <a href='https://github.com/GoogleChrome/lighthouse/blob/master/docs/readme.md#using-programmatically'>â€œUsing Lighthouse Programmaticallyâ€</a> for details."}](./timespans.png)

3. **Set up a virtual machine** that would run tests on demand. This might be a simple EC2 instance in AWS or a physical machine.

   - **Stable configuration.** Make sure that the machine configuration stays the same over time! If itâ€™s faster today and slower tomorrow, the tests would also return better values today and worse values tomorrow
   - **One test at a time.** And make sure the machine never runs several tests in parallel. If you run two tests in parallel, each would steal a part of CPU capacity from the other â€“ and report worse numbers

4. **Run tests and collect measurements.** Every time you need to run a synthetic test, run it on that machine and collect the measurements. Use a tool like [Playwright](https://playwright.dev) or [Puppeteer](https://github.com/puppeteer/puppeteer) to launch the app in a headless browser and click it around like a user would do.

   - [[sidenote|`page.evaluate()`: [Playwright docs](https://playwright.dev/docs/evaluating) Â· [Puppeteer docs](https://puppeteer.github.io/puppeteer/docs/next/puppeteer.page.evaluate/)]]
     | **If you instrumented interactions manually:** store measurements in a global variable (like `window.myPerfMeasurements`) and then read them with `page.evaluate()`
   - **If you use Lighthouseâ€™s Timespan mode:** Playwright and Puppeteer work well with Lighthouse. [Code example](https://web.dev/lighthouse-user-flows/#timespans)

5. **Compare with the last 4-40 runs.** _Do not_ compare the measurements to the previous run. Instead, compare measurements with an average of the last 4-40 runs. (See [â€œFixing Performance Regressions Before they Happenâ€](https://netflixtechblog.com/fixing-performance-regressions-before-they-happen-eab2602b86fe) in Netflix Tech Blog for why this matters.)

[[note]]
| **Disclaimer:** my previous experiments with synthetic testing failed: thereâ€™s been too much noise to catch any regressions. But that was before I learned [how Netflix dealt with the same issue](https://netflixtechblog.com/fixing-performance-regressions-before-they-happen-eab2602b86fe).

# Othersâ€™ Experiences

Here are some of my clientâ€™s experiences with render performance monitoring:

- **Client F.** tracks both significant interactions and long tasks in their warehouse. They do not use `afterFrame` â€“ instead, every interaction uses an individual tracking approach. Theyâ€™ve been tracking metrics like this for several years, and itâ€™s been a success: metrics clearly show when something gets slower.

- **Client Y.** tracks long tasks and collects them into Sentry. What helped them to make sense of the data was adding a bunch of custom Sentry breadcrumbs around the app. Now, every long task has a history like â€œA user clicked button Aâ€â†’ â€œ2 seconds later, they clicked button Bâ€ â†’ â€œ10 ms later, the long task happenedâ€.

Not every experience was positive, though:

- **Client A.** tried to set up interaction tracking but later disabled it. Their feedback was that it was hard to make sense of the data: â€œthese numbers donâ€™t make any sense with variables like user system resources, app and data sizeâ€.

Have your experience to add? Please share it in replies:

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">(Have you tried something like this in the past? Has it worked? Have you stumbled upon any pitfalls? Please share your experience â¬‡ï¸)</p>&mdash; Ivan Akulov ğŸ‡ºğŸ‡¦ (@iamakulov) <a href="https://twitter.com/iamakulov/status/1533885339168714752?ref_src=twsrc%5Etfw">June 6, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
